\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[backend=biber, style=ieee]{biblatex}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{setspace}

\usetikzlibrary{positioning}
\addbibresource{cosc428.bib}

\begin{document}

\title{
	Identification and Classification of Gambling Dice using Commodity Hardware
}

\author{
	\IEEEauthorblockN{Jesse Patrick Sheehan}
	\IEEEauthorblockA{
		\textit{Department of Electrical and Computer Engineering} \\
		\textit{University of Canterbury}\\
		Christchurch, New Zealand \\
		jps111@uclive.ac.nz
	}
}

\maketitle

\begin{abstract}
	A simple method for identifying dice using common image processing techniques and classifying their values using a convolutional neural network is discussed.
	This method has more general applications than its predecessors and can run on modern consumer devices.
\end{abstract}

\begin{IEEEkeywords}
	dice, gambling, computer vision, machine learning
\end{IEEEkeywords}

\section{Introduction}

Dice value detection is a valuable tool for the gaming industry.
Common image processing and feature detection techniques can be used to identify the position of dice.
Machine learning algoithms can be used to classify the value of the dice.
Consumer-grade hardware devices are now more capable of handling the processing requirements of such methods.
This article offers a simple method of detecting and classifying dice.

\section{Background}

Prior research in this field have taken advantage of numerous methods.

The ``SORTE'' system was commissioned by the Portuguese Gaming Inspection Authorities for use in casinos \cite{Correia1995}.
This system identifies the locations of the pips on all dice and uses this information to infer the values for each.
However, this system requires a birds-eye view of the gaming table and dice.
The lighting around the gaming table is also required to be set up in a very specific manner to avoid reflections on the dice themselves.

The system designed by Lapanja, et al., detects dice values for a mechanical gambling machine \cite{Lapanjaa}.
The method used makes use of color difference to identify the pips and template matching to classify each dice.
This system is limited in that it only works in the gaming machine it was designed for.

The system devised by Huang \cite{Huang2008} uses a modified unsupervised gray clustering algorithm to determine the value of each die.
However, it requires a birds-eye view and the number of dice must be known in advance.

Finally, the algorithm designed by Chung \cite{Chung2009} uses image feature detection and the least distance criterion.
The algorithm detects the pips and then groups the pips into a configuration that makes sense.
This method requires a birds-eye view and has only been tested on up to four dice.

All of these methods have been constrained by the camera angle, the number of dice, or the background surface.
It is with these shortcomings in mind that the following method was devised.

\section{Method}

The image is obtained from some source such as a photo file, a frame from a video file, or a frame from a camera.
Some pre-processing (figure \ref{fig:pre-processing}) is performed.
\begin{enumerate}
	\item The image is converted to grayscale to make subsequent processing faster. The colour information is lost, however this does not cause issues as the dice are usually black and white.
	\item A binary threshold is performed. Again, this reduces the amount of information in the image.
	\item A gaussian blur is applied to the image, this removes some noise.
\end{enumerate}
\begin{figure}
	\centering
	\begin{tikzpicture}[
		rectnode/.style={rectangle, draw=black!60, fill=black!5, very thick, minimum size=5mm},
	]

		% nodes
		\node[rectnode]	(gray) 								{Grayscale};
		\node[rectnode] (threshold) [below=of gray] 		{Threshold};
		\node[rectnode] (blur)  	[below=of threshold] 	{Blur};

		% lines
		\draw[thick, ->] (gray.south) -- (threshold.north);
		\draw[thick, ->] (threshold.south) -- (blur.north);

	\end{tikzpicture}
	\caption{The image pre-processing pipeline.}
	\label{fig:pre-processing}
\end{figure}

The image is now sufficiently clean of noise and feature detection can now take place.
Figure \ref{fig:feature-detection} shows the feature detection process.
\begin{enumerate}
	\item Edge detection using the Canny \cite{canny} algorithm is used. % mention parameters
	\item Contours are then detected using the algorithm described by Suzuki, et al. \cite{Suzuki1985}.
	\item Contours are rejected if they are too large or too small.
	\item Contours are then filtered by their shape. The shape rejection filter (algorithm \ref{alg:shape-rejection}) will reject shapes that are not square enough.
\end{enumerate}
\begin{algorithm}
	\setstretch{1.35}
	\caption{The shape rejection filter as pseudocode.}
	\label{alg:shape-rejection}
	\begin{algorithmic}
		\REQUIRE $0 \leq \delta \leq 1$ be the acceptable error factor
		\REQUIRE $P_n$ be the set of points in the rectangle
		\STATE $E_{12} \leftarrow ||P_2 - P_1||$
		\STATE $E_{34} \leftarrow ||P_4 - P_3||$
		\STATE $\Delta = \frac{|E_{12} - E_{34}|}{max(E_{12}, E_{34})}$
		\IF {$\delta \leq \Delta$} \RETURN \TRUE \ELSE \RETURN \FALSE \ENDIF
	\end{algorithmic}
\end{algorithm}
\begin{figure}
	\centering
	\begin{tikzpicture}[
		rectnode/.style={rectangle, draw=black!60, fill=black!15, very thick, minimum size=5mm},
	]
		
		% nodes
		\node[rectnode] (edge)							{Edge Detection};
		\node[rectnode] (contour) 	[below=of edge] 	{Contour Detection};
		\node[rectnode] (size)		[below=of contour] 	{Contour Size Rejection};
		\node[rectnode] (shape)		[below=of size]		{Contour Shape Rejection};

		% lines
		\draw[thick, ->] (edge.south) -- (contour.north);
		\draw[thick, ->] (contour.south) -- (size.north);
		\draw[thick, ->] (size.south) -- (shape.north);
	\end{tikzpicture}
	\caption{The image feature processing pipeline.}
	\label{fig:feature-detection}
\end{figure}

\section{Results}

\section{Conclusion}

\printbibliography

\end{document}
