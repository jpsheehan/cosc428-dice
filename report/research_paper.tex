\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[backend=biber, style=ieee]{biblatex}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[binary-units]{siunitx}

\usetikzlibrary{positioning}
\addbibresource{cosc428.bib}
\graphicspath{ {./images/} }

\begin{document}

\title{
	Identification and Classification of Gambling Dice using Commodity Hardware
}

\author{
	\IEEEauthorblockN{Jesse Patrick Sheehan}
	\IEEEauthorblockA{
		Supervisor: Richard Green \\
		\textit{Department of Electrical and Computer Engineering} \\
		\textit{University of Canterbury}\\
		Christchurch, New Zealand \\
		jps111@uclive.ac.nz
	}
}

\maketitle

\begin{abstract}
	This paper proposes a method to identify dice values using image processing and machine learning techniques.
	Prior research uses the pips of a die to determine its value, whereas the proposed method detects the outline of the die.
	Canny's edge detection and Suzuki's contour tracing algorithms were used to extract die faces from an image.
	A convolutional neural network was used to classify these die faces and to provide a probable number value.
	The proposed method shows a 90\% success rate in correctly detecting and classifying dice values from a webcam.
\end{abstract}

\begin{IEEEkeywords}
	dice, gambling, computer vision, machine learning
\end{IEEEkeywords}

\section{Introduction}

Dice value detection is a valuable tool for the gaming/gambling industry.
Image recognition has often been used in conjunction with other techniques to protect casinos against cheating \cite{4129523}\cite{Correia1995}.
Common image processing and feature detection methods can be used to identify the position of dice.
Machine learning algorithms can be used to classify the value of the dice.
Consumer-grade hardware devices are now more capable of handling the processing requirements of such methods.
This paper proposes a method of detecting and classifying dice using these techniques.

\section{Background}

% Rather than just a summary of prior related research, write a critical review - that is, mention limitations of any prior research/algorithms cited.

Prior research in this field have taken advantage of numerous methods.

The ``SORTE'' system was commissioned by the Portuguese Gaming Inspection Authorities for use in casinos \cite{Correia1995}.
It identified the locations of the pips on all dice and uses spatial locality to assign values to each.
However, this system required specific dice, a birds-eye view of the surface, and a careful ambient lighting setup.

The system designed by Lapanja, et al., detects dice values for a mechanical gambling machine \cite{Lapanjaa}.
It uses color difference to identify the pips and template matching to classify the value of each die.
This method requires a birds-eye view, a high-contrast background surface, and relies on hard-coded masks for classification.

The system devised by Huang \cite{Huang2008} uses a modified unsupervised gray clustering algorithm. 
However, it requires a birds-eye view, a high-contrast background, and the number of dice to be known in advance.

Finally, the method proposed by Chung \cite{Chung2009} uses the least distance criterion to classify die values.
This method detects the pips and then groups the pips into valid configurations based on the relative distance between each pip.
This method requires a birds-eye view and has only been tested on up to four dice.

All of these methods have been constrained by either the camera angle, the number of dice, or the background surface.

\section{Method}

Contrary to previous research, this method detects the outside of each dice first, then isolates each die and employs a CNN to classify the value.

\subsection{Image Pre-processing}

The image (figure \ref{fig:original}) is obtained from a source such as a file or video stream.
Some pre-processing is performed to remove extraneous information:
\begin{enumerate}
	\item The image is converted to grayscale to make subsequent processing faster. 
	\item A binary threshold is performed. Pixel values below 160 are set to black, and the remainder, to white.
	\item A gaussian blur is applied to the image. A kernel size of 5 was used.
\end{enumerate}
\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{original}
	\caption{The original image from a webcam.}
	\label{fig:original}
\end{figure}

\subsection{Die Face Detection}

The image (figure \ref{fig:blurred}) is now sufficiently clean of noise and feature detection can now take place.
The Canny edge detector \cite{Canny1986} is used to find the edges of the dice.
This will also detect undesirable ``edges'' on the flat background surface due to variations in lighting and texture.
The Suzuki contour tracing algorithm \cite{Suzuki1985} joins the continuous edges.
The contours are then kept if they have the following properties:
\begin{itemize}
	\item They have four points (i.e. are quadrilateral).
	\item They have an area greater than 200 pixels square. This removes any small contours that are artifacts of the lighting.
	\item They are square-ish. The shape rejection filter (algorithm \ref{alg:shape-rejection}) will reject contours that are not square enough. The proposed implementation uses $\delta = 20\%$.
\end{itemize}
\begin{algorithm}
	\setstretch{1.35}
	\caption{The shape rejection filter as pseudocode.}
	\label{alg:shape-rejection}
	\begin{algorithmic}
		\REQUIRE $0 \leq \delta \leq 1$ be the acceptable error factor
		\REQUIRE $P_n$ be the set of points in the quadrilateral
		\STATE $E_{12} \leftarrow ||P_2 - P_1||$
		\STATE $E_{34} \leftarrow ||P_4 - P_3||$
		\STATE $\Delta = \frac{|E_{12} - E_{34}|}{\textnormal{max}(E_{12}, E_{34})}$
		\IF {$\Delta \leq \delta$} \RETURN \TRUE \ELSE \RETURN \FALSE \ENDIF
	\end{algorithmic}
\end{algorithm}
\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{blur}
	\caption{The image after pre-processing has occurred.}
	\label{fig:blurred}
\end{figure}
%\begin{figure}
%	\centering
%	\begin{tikzpicture}[
%		rectnode/.style={rectangle, draw=black!60, fill=black!15, very thick, minimum size=5mm},
%	]
%		
%		% nodes
%		\node[rectnode] (edge)							{Edge Detection};
%		\node[rectnode] (contour) 	[below=of edge] 	{Contour Detection};
%		\node[rectnode] (size)		[below=of contour] 	{Contour Size Rejection};
%		\node[rectnode] (shape)		[below=of size]		{Contour Shape Rejection};
%
%		% lines
%		\draw[thick, ->] (edge.south) -- (contour.north);
%		\draw[thick, ->] (contour.south) -- (size.north);
%		\draw[thick, ->] (size.south) -- (shape.north);
%	\end{tikzpicture}
%	\caption{The image feature processing pipeline.}
%	\label{fig:feature-detection}
%\end{figure}

\subsection{Die Face Transformation}

The location and angle of the die face is now known within the original image (figure \ref{fig:canny}).
Each die face must now be transformed before the CNN can be applied:
\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{canny}
	\caption{The original image with the edges highlighted.}
	\label{fig:canny}
\end{figure}

Each square region must be cropped from the original image and rotated so that it lies flat upon the cartesian axis.
Rotation is performed with an affine rotation transformation.
Each image must be scaled to 64x64 pixels for classification.
The die faces have been isolated (figure \ref{fig:faces}) and can now be passed to the CNN for classification.
\begin{figure}
	\centering
	\includegraphics[width=0.2\textwidth]{faces}
	\caption{The die faces after transformation.}
	\label{fig:faces}
\end{figure}

\subsection{Machine Learning}

Machine learning algorithms are often used to solve problems that would be difficult to solve using traditional computing methods.
A CNN is a class of deep neural networks that has many applications in computer vision, speech recognition, and many other fields \cite{Pena2014}\cite{Madabhushi2016}\cite{Lawrence1997}\cite{Kalchbrenner2014}.
A deep neural network is designed with many layers where the information will pass through.
A model will then be trained on a large dataset with known parameters.
This model can then be used to classify images that it hasn't seen before.

The proposed CNN has 4 layers and uses categorical cross-entropy as its loss function. 
This allows the model to produce probabilities for all six values while being aware that only one is correct.
The model was trained on 1200 images of white and yellow dice that were manually captured and classified.

\subsection{Die Classification}

The CNN determines the probability that the isolated die face has a specific number value.
The largest of these values is selected and the original image is annotated with the most likely number for each dice (figure \ref{fig:annotated}).
\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{annotated}
	\caption{The final image with annotations.}
	\label{fig:annotated}
\end{figure}

\section{Results}

The following results were obtained from a laptop with a $\SI{2.4}{\giga\hertz}$ Intel Core i5 processor and $\SI{8}{\giga\byte}$ of memory.
The software used was OpenCV $4.2.0$, Python $3.8.1$, and Tensorflow $2.2.0$ running on 64-bit Windows 10.
A Logitech C170 webcam with a resolution of 640x360 pixels was used to capture images and videos.

The webcam was setup $\SI{37}{\centi\metre}$ above the surface looking directly down. 
Two white dice (black pips) and two yellow dice (black pips) were rolled 50 times.
The webcam was paused while the results were recorded in a spreadsheet.

Over the 200 rolls, $\SI{95.0}{\percent}$ of the dice were detected, and $\SI{95.5}{\percent}$ of these were correctly classified.
This yields an overall accuracy of $\SI{90.7}{\percent}$.

\section{Conclusion}

\subsection{Future Research}

The dice detector is very sensitive to the lighting conditions and the background surface.
In the future, this should either be constrained or a method to overcome the variations in lighting should be devised.

The number 4 was misclassified as a 2 eight times, and the number 5 was misclassified as a 3 once.
The misclassifications are likely due to the visual similarity of these numbers and the CNN being trained on a small dataset. 
The CNN model should be trained on more images to improve its accuracy in the future.

\printbibliography

\end{document}
